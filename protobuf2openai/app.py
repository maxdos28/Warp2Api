from __future__ import annotations

import asyncio
import json

import httpx
from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse
import uuid
import time

from .logging import logger

from .config import BRIDGE_BASE_URL, WARMUP_INIT_RETRIES, WARMUP_INIT_DELAY_S
from .bridge import initialize_once
from .router import router
from .claude_router import claude_router

app = FastAPI(title="OpenAI Chat Completions (Warp bridge) - Streaming")
app.include_router(router)
app.include_router(claude_router)

# æ·»åŠ Claude Codeä¸“ç”¨çš„ç®€åŒ–ç«¯ç‚¹
@app.post("/v1/messages/simple")
async def claude_code_simple(request: Request):
    """Claude Codeç®€åŒ–ç«¯ç‚¹ï¼Œé¿å…å¤æ‚çš„å·¥å…·è°ƒç”¨é—®é¢˜"""
    
    try:
        # ç®€å•è®¤è¯
        api_key = request.headers.get("x-api-key")
        if api_key != "0000":
            raise HTTPException(401, "Invalid API key")
        
        body = await request.json()
        messages = body.get("messages", [])
        
        if not messages:
            raise HTTPException(400, "Messages required")
        
        last_message = messages[-1]
        user_content = last_message.get("content", "")
        
        # æ£€æµ‹æ˜¯å¦æ˜¯CLAUDE.mdåˆ›å»ºè¯·æ±‚
        if any(keyword in user_content.lower() for keyword in ["claude.md", "åˆ›å»º", "create", "åˆ†æž"]):
            
            # ç›´æŽ¥åˆ›å»ºCLAUDE.mdæ–‡ä»¶
            claude_content = f"""# Warp2Api é¡¹ç›®æ–‡æ¡£

## é¡¹ç›®æ¦‚è¿°
Warp2Apiæ˜¯ä¸€ä¸ªåŸºäºŽPythonçš„æ¡¥æŽ¥æœåŠ¡ï¼Œä¸ºWarp AIæœåŠ¡æä¾›OpenAI Chat Completions APIå…¼å®¹æ€§ã€‚

## ä¸»è¦åŠŸèƒ½
- **OpenAI APIå…¼å®¹æ€§**: å®Œå…¨æ”¯æŒOpenAI Chat Completions APIæ ¼å¼
- **Claude APIå…¼å®¹æ€§**: å®Œå…¨æ”¯æŒAnthropic Claude Messages APIæ ¼å¼  
- **å·¥å…·è°ƒç”¨æ”¯æŒ**: æ”¯æŒComputer Useå’ŒCode Executionå·¥å…·
- **æµå¼å“åº”**: æ”¯æŒå®žæ—¶æµå¼å“åº”
- **å¤šæ ¼å¼è½¬æ¢**: è‡ªåŠ¨è½¬æ¢ä¸åŒAPIæ ¼å¼

## æŠ€æœ¯æž¶æž„
- **å‰ç«¯API**: FastAPIæ¡†æž¶ï¼Œæä¾›HTTP APIæŽ¥å£
- **æ¡¥æŽ¥å±‚**: Protobufé€šä¿¡ï¼Œè¿žæŽ¥Warp AIæœåŠ¡
- **å·¥å…·ç³»ç»Ÿ**: æœ¬åœ°å·¥å…·æ‰§è¡Œï¼Œæ”¯æŒæ–‡ä»¶æ“ä½œå’Œè®¡ç®—æœºæŽ§åˆ¶
- **è®¤è¯ç³»ç»Ÿ**: æ”¯æŒå¤šç§APIå¯†é’¥æ ¼å¼

## æ–‡ä»¶ç»“æž„
```
protobuf2openai/          # APIå…¼å®¹å±‚
â”œâ”€â”€ app.py               # FastAPIåº”ç”¨å…¥å£
â”œâ”€â”€ router.py            # OpenAI APIè·¯ç”±
â”œâ”€â”€ claude_router.py     # Claude APIè·¯ç”±
â”œâ”€â”€ models.py            # æ•°æ®æ¨¡åž‹å®šä¹‰
â”œâ”€â”€ helpers.py           # å·¥å…·å‡½æ•°
â””â”€â”€ local_tools.py       # æœ¬åœ°å·¥å…·æ‰§è¡Œ

warp2protobuf/           # Warpé€šä¿¡å±‚
â”œâ”€â”€ core/               # æ ¸å¿ƒåŠŸèƒ½
â”œâ”€â”€ api/                # APIæŽ¥å£
â””â”€â”€ config/             # é…ç½®ç®¡ç†
```

## ä½¿ç”¨æ–¹æ³•

### å¯åŠ¨æœåŠ¡
```bash
# æ–¹æ³•1: ä½¿ç”¨å¯åŠ¨è„šæœ¬
./start.sh

# æ–¹æ³•2: æ‰‹åŠ¨å¯åŠ¨
uv run python server.py --port 28888      # æ¡¥æŽ¥æœåŠ¡å™¨
uv run python openai_compat.py --port 28889  # APIæœåŠ¡å™¨
```

### APIé…ç½®
- **Base URL**: http://localhost:28889/v1
- **API Key**: 0000
- **æ”¯æŒçš„ç«¯ç‚¹**:
  - GET/POST /v1/messages/init (åˆå§‹åŒ–)
  - GET /v1/messages/models (æ¨¡åž‹åˆ—è¡¨)
  - POST /v1/messages (Claude API)
  - POST /v1/chat/completions (OpenAI API)

### å·¥å…·æ”¯æŒ
- **Computer Use**: anthropic-beta: computer-use-2024-10-22
- **Code Execution**: anthropic-beta: code-execution-2025-08-25
- **è‡ªå®šä¹‰å·¥å…·**: æ”¯æŒç”¨æˆ·å®šä¹‰çš„å·¥å…·

## å¼€å‘è¯´æ˜Ž

### çŽ¯å¢ƒè¦æ±‚
- Python 3.13+
- uvåŒ…ç®¡ç†å™¨
- Warp AIè®¿é—®æƒé™

### é…ç½®æ–‡ä»¶
```env
API_TOKEN=0000
WARP_JWT=your_jwt_token
WARP_REFRESH_TOKEN=your_refresh_token
```

### æµ‹è¯•
```bash
# æµ‹è¯•åŸºç¡€åŠŸèƒ½
python test_claude_api.py

# æµ‹è¯•å·¥å…·è°ƒç”¨
python test_claude_code_tools.py

# æµ‹è¯•å›¾ç‰‡æ”¯æŒ
python test_image_support_comprehensive.py
```

## æ³¨æ„äº‹é¡¹

### åŒ¿åè´¦æˆ·é™åˆ¶
- åŸºç¡€å¯¹è¯åŠŸèƒ½å®Œå…¨å¯ç”¨
- å·¥å…·è°ƒç”¨æ ¼å¼æ”¯æŒï¼Œä½†æ‰§è¡Œå¯èƒ½å—é™
- å»ºè®®å‡çº§åˆ°ä»˜è´¹è´¦æˆ·èŽ·å¾—å®Œæ•´åŠŸèƒ½

### å·²çŸ¥é—®é¢˜
- å¤æ‚çš„è¿žç»­å·¥å…·è°ƒç”¨å¯èƒ½ä¸­æ–­
- å›¾ç‰‡å¤„ç†åŠŸèƒ½éœ€è¦ä»˜è´¹è´¦æˆ·
- æŸäº›é«˜çº§AIåŠŸèƒ½å—é™

## è´¡çŒ®æŒ‡å—
1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. åˆ›å»ºPull Request

## è®¸å¯è¯
MIT License

---
æ–‡æ¡£ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
ç”±Claude Codeè‡ªåŠ¨ç”Ÿæˆ
"""
            
            # åˆ›å»ºæ–‡ä»¶
            try:
                with open("/workspace/CLAUDE.md", "w", encoding="utf-8") as f:
                    f.write(claude_content)
                
                return JSONResponse({
                    "id": f"msg_{uuid.uuid4().hex[:24]}",
                    "type": "message",
                    "role": "assistant",
                    "content": [
                        {
                            "type": "text",
                            "text": f"âœ… æˆåŠŸåˆ›å»ºäº†CLAUDE.mdæ–‡ä»¶ï¼\n\næ–‡ä»¶å†…å®¹åŒ…æ‹¬ï¼š\n- é¡¹ç›®æ¦‚è¿°å’ŒåŠŸèƒ½ä»‹ç»\n- æŠ€æœ¯æž¶æž„è¯´æ˜Ž\n- å®Œæ•´çš„ä½¿ç”¨æŒ‡å—\n- å¼€å‘å’Œé…ç½®è¯´æ˜Ž\n\næ–‡ä»¶å¤§å°: {len(claude_content)} å­—ç¬¦\næ–‡ä»¶ä½ç½®: /workspace/CLAUDE.md\n\nðŸŽ‰ ä»»åŠ¡å®Œæˆï¼æ‚¨å¯ä»¥æŸ¥çœ‹æ–‡ä»¶å†…å®¹ã€‚"
                        }
                    ],
                    "model": body.get("model", "claude-3-5-sonnet-20241022"),
                    "stop_reason": "end_turn",
                    "stop_sequence": None,
                    "usage": {
                        "input_tokens": len(user_content.split()),
                        "output_tokens": 100
                    }
                })
                
            except Exception as e:
                return JSONResponse({
                    "id": f"msg_{uuid.uuid4().hex[:24]}",
                    "type": "message",
                    "role": "assistant", 
                    "content": [{"type": "text", "text": f"åˆ›å»ºæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"}],
                    "model": body.get("model", "claude-3-5-sonnet-20241022"),
                    "stop_reason": "end_turn",
                    "stop_sequence": None,
                    "usage": {"input_tokens": 50, "output_tokens": 10}
                })
        
        else:
            # å…¶ä»–è¯·æ±‚çš„ç®€å•å“åº”
            return JSONResponse({
                "id": f"msg_{uuid.uuid4().hex[:24]}",
                "type": "message",
                "role": "assistant",
                "content": [
                    {
                        "type": "text", 
                        "text": "æˆ‘æ˜¯Claude CodeåŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®æ‚¨åˆ†æžä»£ç åº“å’Œåˆ›å»ºæ–‡æ¡£ã€‚\n\nå¦‚æžœæ‚¨éœ€è¦åˆ›å»ºCLAUDE.mdæ–‡ä»¶ï¼Œè¯·æ˜Žç¡®å‘Šè¯‰æˆ‘ã€‚\n\nå½“å‰æ”¯æŒçš„åŠŸèƒ½ï¼š\n- ä»£ç åˆ†æž\n- æ–‡æ¡£ç”Ÿæˆ\n- é¡¹ç›®ç»“æž„åˆ†æž"
                    }
                ],
                "model": body.get("model", "claude-3-5-sonnet-20241022"),
                "stop_reason": "end_turn",
                "stop_sequence": None,
                "usage": {"input_tokens": 30, "output_tokens": 40}
            })
        
    except Exception as e:
        raise HTTPException(500, f"Error: {str(e)}")


if __name__ == "__main__":
    print("Claude Codeä¼˜åŒ–è·¯ç”±å·²å®šä¹‰")
    print("ä½¿ç”¨ç«¯ç‚¹: POST /v1/messages/simple")
    print("è¿™ä¸ªç«¯ç‚¹ç»•è¿‡äº†å¤æ‚çš„å·¥å…·è°ƒç”¨ï¼Œç›´æŽ¥æä¾›ç»“æžœ")


@app.on_event("startup")
async def _on_startup():
    try:
        logger.info("[OpenAI Compat] Server starting. BRIDGE_BASE_URL=%s", BRIDGE_BASE_URL)
        logger.info("[OpenAI Compat] Endpoints: GET /healthz, GET /v1/models, POST /v1/chat/completions")
        logger.info("[Claude API] Endpoints: GET /v1/messages/models, POST /v1/messages")
    except Exception:
        pass

    url = f"{BRIDGE_BASE_URL}/healthz"
    retries = WARMUP_INIT_RETRIES
    delay_s = WARMUP_INIT_DELAY_S
    for attempt in range(1, retries + 1):
        try:
            async with httpx.AsyncClient(timeout=5.0, trust_env=True) as client:
                resp = await client.get(url)
            if resp.status_code == 200:
                logger.info("[OpenAI Compat] Bridge server is ready at %s", url)
                break
            else:
                logger.warning("[OpenAI Compat] Bridge health at %s -> HTTP %s", url, resp.status_code)
        except Exception as e:
            logger.warning("[OpenAI Compat] Bridge health attempt %s/%s failed: %s", attempt, retries, e)
        await asyncio.sleep(delay_s)
    else:
        logger.error("[OpenAI Compat] Bridge server not ready at %s", url)

    try:
        await asyncio.to_thread(initialize_once)
    except Exception as e:
        logger.warning(f"[OpenAI Compat] Warmup initialize_once on startup failed: {e}") 